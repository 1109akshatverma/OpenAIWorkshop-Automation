page-number-291-line-number-29,"'Data parallelism'
'Data parallelism is the easiest to implement of the two distriuted training approaches,'
'and is sufficient for most use cases.'
'In this approach, the data is divided into partitions, where the numer of partitions is'
'equal to the total numer of availale nodes, in the compute cluster. The model is'
'copied in each of these worker nodes, and each worker operates on its own suset of'
'the data. Keep in mind that each node has to have the capacity to support the model'
""that's eing trained, that is the model has to entirely fit on each node. The following""
'diagram provides a visual demonstration of this approach.'
"
