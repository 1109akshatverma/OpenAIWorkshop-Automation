{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "### 1. [Introduction](#Introduction)\n",
    "### 2. [Set Up Python Virtual Environment (venv), Dependencies, and Jupyter Instance](#Set-Up-Python-Virtual-Environment-(venv),-Dependencies,-and-Jupyter-Instance)\n",
    "### 3. [Overview of the Chat Completion API](#Overview-of-the-Chat-Completion-API)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ChatGPT and GPT-4 models are optimized for conversational interfaces and work differently than the older GPT-3 models. They are conversation-in and message-out, and require input formatted in a specific chat-like transcript format. Azure OpenAI provides two different options for interacting with these models: Chat Completion API and Completion API with Chat Markup Language (ChatML). \n",
    "The Chat Completion API is the preferred method for accessing these models, while ChatML provides lower level access but requires additional input validation and only supports ChatGPT models. It's important to use the techniques described in the article to get the best results from the new models.\n",
    "\n",
    "This notebook will cover the aspects of the Chat Completion Python API with conversation, roles (system, assistant, user) and examples of different usage scenarios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Python Virtual Environment (venv), Dependencies, and Jupyter Instance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Python Virtual Environment (venv)\n",
    "\n",
    "**Set up your environment (You can skip this if you have a working environment)**\n",
    "**These commands should be entered in the command line or console**\n",
    "\n",
    "**Instructions as written are for command prompt within VS Code**\n",
    "\n",
    "**Instructions were written for Python 3.10.4**\n",
    "\n",
    "**Create virtual environment to start - the first portion of the code below**\n",
    "```commandline\n",
    "C:\\<Location>\\<To your python install>\\python -m venv C:\\<Location>\\<You want to create your virtual environment>\n",
    "```\n",
    "\n",
    "**Change directory to new virtual environment and activate**\n",
    "```commandline\n",
    "cd C:\\<Location>\\<You created your virtual environment in>\\scripts\n",
    "\n",
    "Activate\n",
    "```\n",
    "\n",
    "**Change directory to code repository**\n",
    "```commandline\n",
    "cd C:\\<Location>\\<To your code repository>\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install dependencies\n",
    "\n",
    "In the command line, install the following packages via pip install\n",
    "\n",
    "```commandline\n",
    " pip install <package name>\n",
    " ```\n",
    "\n",
    "* openai\n",
    "* jupyterlab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Launch Jupyter instance\n",
    "\n",
    "Launch your Jupyter instance by starting the jupyter server:\n",
    "\n",
    "```commandline\n",
    "jupyter-lab\n",
    "```\n",
    "\n",
    "You may need to select your virtual environment as the kernel for your notebook - this can be done in the top right corner of your VS Code Instance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Environment Variables\n",
    "\n",
    "Add in the environment variables for your OpenAI API Key and API Base URL. You can find these values in the Azure Portal under your OpenAI resource.\n",
    "\n",
    "We can add in new variables as such:\n",
    "Add in new environment variables\n",
    "os.environ['NEW_VARIABLE_NAME'] = '/new/value'\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR OPENAI API KEY'\n",
    "os.environ['OPENAI_API_BASE'] = '<YOUR OPENAI API ENDPOINT URL>'\n",
    "os.environ['OPEN_AI_ENGINE'] = '<NAME UNDER WHICH YOU DEPLOYED YOUR MODEL>'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your environment variables here or hard-code them (not recommended)\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'a3bb7d6279d94ae9a61905b2845cbe64'\n",
    "os.environ['OPENAI_API_BASE'] = 'https://embeddings-openaiplayground.openai.azure.com/'\n",
    "os.environ['OPEN_AI_ENGINE'] = 'chat'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call os.getenv() to retrieve the value of an environment variable. If the variable does not exist, os.getenv() returns None. In that case you may need to verify\n",
    "that you are using the same name as the environment variable you created or try re-running the os.environ command.\n",
    "\n",
    "```python\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\" \n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")  # Your Azure OpenAI resource's endpoint value.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Your Azure OpenAI resource's key value.\n",
    "openai_engine = os.getenv(\"OPEN_AI_ENGINE\") # The name you gave your OpenAI Model deployment in Azure\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\" \n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")  # Your Azure OpenAI resource's endpoint value.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Your Azure OpenAI resource's key value.\n",
    "openai_engine = os.getenv(\"OPEN_AI_ENGINE\") # The name you gave your OpenAI Model deployment in Azure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Chat Completion API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The following parameters aren't available with the new ChatGPT and GPT-4 models: **logprobs**, **best_of**, and **echo**. If you set any of these parameters, you'll get an error. gpt-35-turbo is equivalent to the gpt-3.5-turbo model from OpenAI.\n",
    "\n",
    "##### ChatCompletion.create()\n",
    "OpenAI trained the ChatGPT and GPT-4 models to accept input formatted as a conversation. The messages parameter takes an array of dictionaries with a conversation organized by role. The three types of roles are:\n",
    "\n",
    "* system\n",
    "* assistant\n",
    "* user \n",
    "\n",
    "A sample input containing a simple system message, a one-shot example of a user and assistant interacting, and the final \"actual\" user-supplied prompt is shown below:\n",
    "\n",
    "```json\n",
    "{\"role\": \"system\", \"content\": \"Provide some context and/or instructions to the model.\"},\n",
    "{\"role\": \"user\", \"content\": \"Example question goes here.\"}\n",
    "{\"role\": \"assistant\", \"content\": \"Example answer goes here.\"}\n",
    "{\"role\": \"user\", \"content\": \"First question/message for the model to actually respond to.\"}\n",
    "```\n",
    "\n",
    "Let's dive deeper into our 3 possible roles types of system, user, and assistant.\n",
    "\n",
    "##### System Role\n",
    "The system role, also known as the system message, is included at the beginning of the array. This message provides the initial instructions to the model. You can provide various information in the system role including:\n",
    "\n",
    "* A brief description of the assistant\n",
    "* Personality traits of the assistant\n",
    "* Instructions or rules you would like the assistant to follow\n",
    "* Data or information needed for the model, such as relevant questions from an FAQ\n",
    "\n",
    "You can customize the system role for your use case or just include basic instructions. The system role/message is optional, but it's recommended to at least include a basic one to get the best results.\n",
    "\n",
    "##### Assistant Role\n",
    "\n",
    "The assistant role is that of OpenAI or your assistant. You can omit this role in an intial ChatCompletion.create() call if desired, though it is required if you are going to pass a one-shot or few-shot example through the messages parameter. \n",
    "\n",
    "Let's take a look at some examples of the Chat Completion API in action.\n",
    "\n",
    "##### User Role\n",
    "\n",
    "The user role is the message that the user sends to the assistant. This is the message that the model will respond to. The user role is required for the model to respond.\n",
    "\n",
    "> **Note:** To trigger a response from the model, you should end with a user message indicating that it's the assistant's turn to respond. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the max_tokens parameter has been set to 500 - this is not requried but suggested that you increase the max tokens to allow for longer responses\n",
    "# so they do not get cut-off mid-response.\n",
    "\n",
    "# openai_engine parameter is the name supplied to the deployed OpenAI model (This is something that is set at the time the model is deployed)\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=openai_engine, # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the difference between garbanzo beans and chickpeas?\"},\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we supplied two of our roles: system and user. The system message is very simple - it just provides some context for the model. The user message is the prompt that the model will respond to. Let's see what the model returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Garbanzo beans and chickpeas are actually the same thing! \\\"Garbanzo\\\" is the Spanish name for the legume, while \\\"chickpea\\\" is the English name. They are a member of the pea family and are often used in dishes like hummus, falafel, and salads.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1679950238,\n",
      "  \"id\": \"chatcmpl-6yo5WwY41wIK9eM8ETuhpjth2vxQQ\",\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 67,\n",
      "    \"prompt_tokens\": 37,\n",
      "    \"total_tokens\": 104\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our print(response)'s output above we can see we get an array of responses. We'll mainly focus on the \"content\" within the \"message\" returned under \"choices\". However, it may be helpful to understand a few of the other views, such as \"finish_reason\". Every response includes a finish_reason. The possible values for finish_reason are:\n",
    "\n",
    "* **stop**: API returned complete model output.\n",
    "* **length**: Incomplete model output due to max_tokens parameter or token limit.\n",
    "* **content_filter**: Omitted content due to a flag from our content filters.\n",
    "* **null**:API response still in progress or incomplete.\n",
    "\n",
    "The material supplied under \"usage\" can also be helpful when trying to keep track of the number of tokens used in your request. The \"usage\" object includes the following information:\n",
    "* **completion_tokens**: The number of tokens used to complete the prompt - this should typically be from the \"assistant\" role.\n",
    "* **prompt_tokens**: The number of tokens used to prompt the model - this should typically be from the \"user\" role.\n",
    "* **total_tokens**: The total number of tokens used in the request.\n",
    "\n",
    "However, we're most interested in the \"content\" within the \"message\" returned under \"choices\". Let's take a look at the \"content\" returned in the response above by printing out just the assistant's response by accessing the \"content\" within the \"message\" returned under \"choices\":\n",
    "\n",
    "Copy and paste this code into the cell below and run it to see the assistant's response:\n",
    "```python\n",
    "print(response['choices'][0]['message']['content'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbanzo beans and chickpeas are actually the same thing! \"Garbanzo\" is the Spanish name for the legume, while \"chickpea\" is the English name. They are a member of the pea family and are often used in dishes like hummus, falafel, and salads.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our print(response['choices'][0]['message']['content'])'s output above we can see that the \"assistant\" responded by informing the user that both Garbanzo and chickpeas refer to the same. In the next sections, we'll focus on how we can refine our ChatCompletions.create() calls to get more specific responses or fit different scenarios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example ChatCompletion.create() Calls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our basic system message previously was:\n",
    "```json\n",
    "{\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"}\n",
    "```\n",
    "\n",
    "This gives us an assistant who approximates the initial OpenAI ChatGPT assistant. Let's see what happens if we change the system message to:\n",
    "```json\n",
    "{\"role\": \"system\", \"content\": \"Assistant is an intelligent chatbot designed to help users answer their tax related questions.\\\n",
    "        Instructions:\\\n",
    "        - Only answer questions related to taxes.\\\n",
    "        - If you are unsure of an answer, you can say 'I do not know' or 'I am not sure' and recommend users go to the IRS website for more information. \"},\n",
    "```\n",
    "\n",
    "To create an assistant to help us file our taxes.\n",
    "\n",
    "You can copy and paste the above system role message into the cell below and run it to see the assistant's response:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tax deadline for individuals typically falls on April 15th each year. However, due to the COVID-19 pandemic, the tax deadline for 2020 was extended to July 15th. It's always a good idea to double-check with the IRS website or a tax professional to confirm the current year's deadline.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=openai_engine, # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Assistant is an intelligent chatbot designed to help users answer their tax related questions.\\\n",
    "        Instructions:\\\n",
    "        - Only answer questions related to taxes.\\\n",
    "        - If you are unsure of an answer, you can say 'I do not know' or 'I am not sure' and recommend users go to the IRS website for more information. \"}, # Paste the system role message from above between the two curly braces\n",
    "        {\"role\": \"user\", \"content\": \"When are my taxes due?\"},\n",
    "    ],\n",
    "    temperature=0.50,\n",
    "    max_tokens=500,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the answer above that our assistant got the *typical* date when federal taxes are due correct - April 15th and notes that deadlines were extended during the COVID-19 Pandemic.\n",
    "However, in 2023, April 15th happens to fall on a Saturday, so the deadline has been pushed back to April 18th. Let's see if we can get our assistant to respond with the correct date.\n",
    "\n",
    "To do so, let's provide our assistant the correct answer and reasoning in a few-shot example. We'll add the following to our messages call in ChatCompletion.create():\n",
    "```json\n",
    "{\"role\": \"system\", \"content\": \"Assistant is an intelligent chatbot designed to help users answer their tax related questions. \"},\n",
    "{\"role\": \"user\", \"content\": \"When do I need to file my taxes by?\"},\n",
    "{\"role\": \"assistant\", \"content\": \"In 2023, you will need to file your taxes by April 18th. The date falls after the usual April 15th deadline because April 15th falls on a Saturday in 2023. For more details, see https://www.irs.gov/filing/individuals/when-to-file.\"},\n",
    "{\"role\": \"user\", \"content\": \"How can I check the status of my tax refund?\"},\n",
    "{\"role\": \"assistant\", \"content\": \"You can check the status of your tax refund by visiting https://www.irs.gov/refunds\"},\n",
    "```\n",
    "\n",
    "Here what we are doing is providing our assistant with a few-shot example of a user asking about the tax deadline and our assistant providing the correct answer. We are also providing our assistant with an example of how to respond if a user requests information about their tax refund."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2023, you will need to file your taxes by April 18th. The date falls after the usual April 15th deadline because April 15th falls on a Saturday in 2023. For more details, see https://www.irs.gov/filing/individuals/when-to-file.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=openai_engine, # The deployment name you chose when you deployed the ChatGPT or GPT-4 model.\n",
    "    messages=[\n",
    "        PASTE CONTENT FROM ABOVE HERE # Paste in the role messages from above\n",
    "        {\"role\": \"user\", \"content\": \"When do I need to file my taxes by?\"},\n",
    "    ],\n",
    "    temperature=0.50,\n",
    "    max_tokens=500,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
